{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ugywjd/006975/blob/master/ai12_sc41x_%EB%B0%95%ED%9A%A8%EC%A0%95.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVNDxiWkw5y7"
      },
      "source": [
        "<img src='https://user-images.githubusercontent.com/6457691/90080969-0f758d00-dd47-11ea-8191-fa12fd2054a7.png' width = '200' align = 'right'>\n",
        "\n",
        "## AI SC41x\n",
        "\n",
        "---\n",
        "# Sprint Challenge - 신경망(Neural Network) 기본기 다지기\n",
        "\n",
        "Table of Problems\n",
        "\n",
        "1. 신경망 정의하기 \n",
        "2. 퍼셉트론 정의\n",
        "    - 퍼셉트론(Perceptron)\n",
        "    - 다층 퍼셉트론(Multilayer Perceptron)\n",
        "    - 분석과 비교\n",
        "4. Keras 사용하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9qf0cRbw5y8"
      },
      "source": [
        "<a id=\"Q1\"></a>\n",
        "## 1. 신경망 용어 정의\n",
        "### 1.1 아래에 주어진 신경망 개념에 사용 되는 용어들을 자신만의 언어로 정의해보세요\n",
        "꼭 \"자신의 언어\"로 써보시고, 정리해보고, 요약해보세요 :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOribBxDQvjc"
      },
      "source": [
        "- **Neuron:**\n",
        "사람의 뉴런이 서로간의 신호를 보내듯, 이를 모방하여 인공적으로 구축했다.\n",
        "- **Input Layer:**\n",
        "딥러닝이 필요한 데이터의 입력이 시작디는 곳 계산 없이 값을 전달하기만 한다\n",
        "- **Hidden Layer:**\n",
        "입력된 신호를 바탕으로 가중치, 편향 등이 연산되는 층\n",
        "- **Output Layer:**\n",
        "연산을 마친 은닉층의 값이 출력되는 곳\n",
        "- **Activation Function:**\n",
        "딥러닝 과정에서 계산된 가중합을 얼마 만큼의 신호르 출력할지 결정한다\n",
        "- **Back Propagation:**\n",
        "출력층에서 입력층으로 손실정보를 전달해 가중치를 얼마나 업데이트 해야할지 구한다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdcS-Jx2w5y8"
      },
      "source": [
        "### 1.2 역전파 설명해보기\n",
        "이번에는 역전파 (Back Propagation)를 조금 더 디테일하게 설명해보겠습니다. \n",
        "<br> <b>초등학생</b>에게 설명한다는 생각으로 단어들을 선정해 주세요. <i>외부 자료나 이미지를 설명에 활용하셔도 좋습니다</i>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iBZA8EQuw5y8"
      },
      "outputs": [],
      "source": [
        "# 여기에 답변하시고, Cell을 Markdown으로 변경해서 입력하세요."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "신경망의 학습은 데이터가 입력되면 가중치\u001c 및 활성화 함수 연산을 반복적으로 수행해 값을 출력하게 됩니다.\n",
        "이 때 가중치는 각 신호가 연산에 얼마나 기여하는지, 그리고 활성화 함수는 신호의 총합을 출력 신호로 변환하는 함수이다. \n",
        "그리고 실제값과 예측값의 차이를 계산하여 가중치를 갱신한다. 이러한 일련의 과정을 순전파라고 칭한다.\n",
        "순전파와 반대로 정보를 전달하는데, 가중치를 얼마나 업데이트 해야할지 구하기 위해 이러한 과정을 거치게 된다. \n",
        "신경망은 매번 손실을 줄이는 방향으로 가중치를 업데이트를 하고 이 과정을 역전파라고 한다."
      ],
      "metadata": {
        "id": "OgMfBLwuh8Vv"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7ZSjf9Uw5y8"
      },
      "source": [
        "### 1.3 퍼셉트론 정의해보기\n",
        "신경망 수업 첫날에 들었었던 퍼셉트론의 간단한 개념으로 예측하는 과정을 설명해보세요. <br> <b>입력</b>에서 <b>출력</b>으로 어떻게 변경되는 지 단계별로 설명해보세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yaJoCMf1w5y8"
      },
      "outputs": [],
      "source": [
        "# 여기에 답변하시고, Cell을 Markdown으로 변경해서 입력하세요."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "퍼셉트론이란 신경망을 이루는 기본단위이며, 다수의 신호를 입력으로 받아 하나의 신호를 출력하는 구조이다\n",
        "퍼셉트론의 첫 단계는 가중치-편향 연산이다. 입력된 신호를 각 가중치와 곱하고 그 결과를 더해주는 가중합을 구한다\n",
        "계산된 가중합은 얼마만큼의 신호로 출력할지 결정해주는 활성화 함수를 사용하게 된다.\n",
        "활성화 함수는 여러종류가 있어 데이터의 종류에 따라 달리 사용된다.(ex. Sigmoid, ReLU, Softmax)\n",
        "활성화 함수를 사용한 결과값을 출력값으로 도출하게 된다."
      ],
      "metadata": {
        "id": "oSwZ95EAh_Js"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1A2h2zpCw5y8"
      },
      "source": [
        "<a id=\"Q2\"></a>\n",
        "## 2. 단순 퍼셉트론\n",
        "\n",
        "이번에는 TensorFlow, keras를 사용하여 두 개의 신경망을 직접 구축한 뒤,\n",
        "<br> 아래 임의로 제공 된 $X, y$를 이용하여 두 모델에 적용한 뒤 결과를 비교해보세요. \n",
        "먼저 사용할 데이터는 다음과 같습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "TWdXFK9Yw5y8",
        "outputId": "0da4a5d0-25d8-432b-eee8-9c6d3b49fa6d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7fbca4baa310>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "xx, yy = np.meshgrid(np.linspace(-3, 3, 50),\n",
        "                     np.linspace(-3, 3, 50))\n",
        "rng = np.random.RandomState(0)\n",
        "\n",
        "\n",
        "\"model1과 model2를 구축할 때 아래의 X & y를 사용하세요\"\n",
        "X = rng.randn(300, 2)\n",
        "y = np.array(np.logical_xor(X[:, 0] > 0, X[:, 1] > 0), \n",
        "             dtype=int)\n",
        "\n",
        "plt.scatter(X[:,0], X[:,1], s=y)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjr4UoQXw5y8"
      },
      "source": [
        "### 단순 퍼셉트론 구현\n",
        "Keras로 <b>sigmoid activation function</b>을 포함한 dense layer 1개가 있는</b> `model1`을 만들어 학습시키고 `h1`에 저장하세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKZXIC1ew5y8",
        "outputId": "6d954a0a-a070-4800-b0e9-342c7fa79c83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "10/10 [==============================] - 1s 2ms/step - loss: 1.0379 - accuracy: 0.4533\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0278 - accuracy: 0.4567\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0169 - accuracy: 0.4567\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.0070 - accuracy: 0.4567\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.9974 - accuracy: 0.4567\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.9877 - accuracy: 0.4567\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9788 - accuracy: 0.4567\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.9696 - accuracy: 0.4533\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.9606 - accuracy: 0.4567\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.9516 - accuracy: 0.4567\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.9424 - accuracy: 0.4567\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9337 - accuracy: 0.4567\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.9257 - accuracy: 0.4600\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.9175 - accuracy: 0.4600\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.9093 - accuracy: 0.4600\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.9013 - accuracy: 0.4567\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.8934 - accuracy: 0.4567\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.8858 - accuracy: 0.4600\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.8782 - accuracy: 0.4600\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.8708 - accuracy: 0.4600\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8641 - accuracy: 0.4600\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.8573 - accuracy: 0.4633\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.8510 - accuracy: 0.4633\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.8445 - accuracy: 0.4633\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.8388 - accuracy: 0.4667\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.8327 - accuracy: 0.4667\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.8264 - accuracy: 0.4633\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.8209 - accuracy: 0.4633\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.8154 - accuracy: 0.4633\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.8103 - accuracy: 0.4633\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.8051 - accuracy: 0.4633\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.8001 - accuracy: 0.4667\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7951 - accuracy: 0.4633\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7907 - accuracy: 0.4667\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7863 - accuracy: 0.4733\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7823 - accuracy: 0.4733\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7781 - accuracy: 0.4767\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7739 - accuracy: 0.4800\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7701 - accuracy: 0.4867\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7664 - accuracy: 0.4900\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7628 - accuracy: 0.4900\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7595 - accuracy: 0.4900\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7564 - accuracy: 0.4933\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7532 - accuracy: 0.4933\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7501 - accuracy: 0.4933\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7471 - accuracy: 0.4933\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7445 - accuracy: 0.4933\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7421 - accuracy: 0.4967\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7395 - accuracy: 0.5067\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7374 - accuracy: 0.5033\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7348 - accuracy: 0.5100\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7324 - accuracy: 0.5067\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7304 - accuracy: 0.5167\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7283 - accuracy: 0.5200\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7265 - accuracy: 0.5200\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7247 - accuracy: 0.5200\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7230 - accuracy: 0.5167\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7212 - accuracy: 0.5233\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7193 - accuracy: 0.5267\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7177 - accuracy: 0.5267\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7163 - accuracy: 0.5267\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7149 - accuracy: 0.5467\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7135 - accuracy: 0.5533\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7124 - accuracy: 0.5567\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7114 - accuracy: 0.5567\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7101 - accuracy: 0.5633\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7090 - accuracy: 0.5667\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7079 - accuracy: 0.5700\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7070 - accuracy: 0.5700\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7059 - accuracy: 0.5700\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.7048 - accuracy: 0.5767\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7041 - accuracy: 0.5800\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7030 - accuracy: 0.5867\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7023 - accuracy: 0.5933\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7016 - accuracy: 0.5900\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7008 - accuracy: 0.5867\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7001 - accuracy: 0.5867\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6995 - accuracy: 0.5600\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6988 - accuracy: 0.5567\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6984 - accuracy: 0.5500\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6977 - accuracy: 0.5467\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6971 - accuracy: 0.5633\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6965 - accuracy: 0.5633\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6960 - accuracy: 0.5300\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6955 - accuracy: 0.5233\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6950 - accuracy: 0.5200\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6946 - accuracy: 0.5100\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6943 - accuracy: 0.5100\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6939 - accuracy: 0.5033\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.4967\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4900\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.4933\n",
            "Epoch 93/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6925 - accuracy: 0.4967\n",
            "Epoch 94/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6921 - accuracy: 0.5000\n",
            "Epoch 95/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6919 - accuracy: 0.4967\n",
            "Epoch 96/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6916 - accuracy: 0.5000\n",
            "Epoch 97/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6915 - accuracy: 0.4933\n",
            "Epoch 98/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6912 - accuracy: 0.5033\n",
            "Epoch 99/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6910 - accuracy: 0.5067\n",
            "Epoch 100/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6907 - accuracy: 0.5100\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "model1 = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model1.compile(optimizer='sgd',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "h1 = model1.fit(X, y, epochs=100)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1.evaluate(X, y, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0D7aN8YpkZmd",
        "outputId": "034364d3-85c6-4659-ac36-e4fa0dd2103a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 - 0s - loss: 0.6905 - accuracy: 0.5167 - 361ms/epoch - 36ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6905480027198792, 0.5166666507720947]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ugkziwew5y8"
      },
      "source": [
        "\n",
        "### Multi-Layer Perceptron (MLP)\n",
        "이번에는 여러층의 레이어들을 쌓은 MLP 모델을 만들어보겠습니다. 아래는 간략한 가이드입니다 :\n",
        "- 2개의 은닉층 (출력 수를 맞추는 것까지 3개의 Dense를 사용할 것은 추천)\n",
        "- 노드의 개수는 8-32개 내에서 변경해서 사용해보세요.\n",
        "- Activation function과 optimizer는 이번 주에 배운 것들 중에서 자유롭게 골라보세요.\n",
        "- 아래 만들어진 Callback function을 모델에 통합해서 사용하세요\n",
        "\n",
        "MLP로 만들어진 `model2` 를 만들어 학습하고 `h2`에 저장하세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "6BoIn7iBw5y8"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback): \n",
        "    def on_epoch_end(self, epoch, logs={}): \n",
        "        if(logs.get('accuracy') > .90):   \n",
        "            self.model.stop_training = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658
        },
        "id": "B63dciqEw5y8",
        "outputId": "b0fa07f7-fde0-465a-940a-a1cc12afb425"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-7a3def2d7c6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m               metrics=['accuracy'])\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mh2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 859, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential_4\" is incompatible with the layer: expected shape=(None, 28, 28), found shape=(None, 2)\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "\n",
        "model2 = Sequential() \n",
        "model2.add(Flatten(input_shape=(28, 28)))\n",
        "model2.add(Dense(128, activation='relu'))\n",
        "model2.add(Dense(100, activation='softmax'))\n",
        "\n",
        "model2.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "h2 = model2.fit(X, y, epochs=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xn2TsE76w5y8"
      },
      "source": [
        "### Analyze and Compare\n",
        "\n",
        "코드를 시작하기 전에 추가 라이브러리를 설치해야 합니다. 스프린트 과제에 사용 중인 환경에 패키지 `mlxtend`를 설치합니다. 설치코드를 직접 제작해보세요. 기존 자료들을 참고하면 쉽게 설치할 수 있을 것입니다. \n",
        "\n",
        "아래 셀은 모형의 의사결정 경계도(\"model1\" 및 \"model2\")를 생성합니다. 그림을 검토합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96hsbGktVlgL"
      },
      "outputs": [],
      "source": [
        "# mlxtend 라이브러리를 설치합니다\n",
        "!pip install mlxtend"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ox13rgjTw5y8"
      },
      "outputs": [],
      "source": [
        "# 이 셀의 코드는 변경하지 마세요\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from mlxtend.plotting import plot_decision_regions\n",
        "\n",
        "h = .02  # step size in the mesh\n",
        "\n",
        "# create a mesh to plot in\n",
        "x_min, x_max = X[:, 0].min() - .2, X[:, 0].max() + .2\n",
        "y_min, y_max = X[:, 1].min() - .2, X[:, 1].max() + .2\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
        "                     np.arange(y_min, y_max, h))\n",
        "\n",
        "fig = plt.figure(figsize=(12,6))\n",
        "\n",
        "\n",
        "for clf, hist, name, grd in zip([model1,model2], [h1, h2],['Perceptron', 'Multi-Layer Perceptron'],[1,2]):\n",
        "\n",
        "    ax = plt.subplot(1,2, grd)\n",
        "    fig = plot_decision_regions(X=X, y=y, clf=clf, legend=2)\n",
        "    title = f\"{name} with {hist.history['accuracy'][-1]:,.2f} Accuracy\"\n",
        "    plt.title(title)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qBWszwMw5y8"
      },
      "source": [
        "#### 대부분의 Perceptron(\"model1\")의 정확도가 50-70% 정도로 나오실 것인데요, 왜 그것밖에 되지 않을까요? <br> 데이터 X와 레이블 y의 관계를 보다 정확하게 학습할 수 있는 다층 퍼셉트론의 구조적인 특징은 무엇일까요? (설명을 하실 때 우리가 배웠었던 특징 추출의 관점에서 설명을 해보시길 바랍니다.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9-bIuHnw5y8"
      },
      "outputs": [],
      "source": [
        "# 여기에 답변하시고, Cell을 Markdown으로 변경해서 입력하세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYEPmr-_w5y8"
      },
      "source": [
        "## 3. Keras MLP 튜닝\n",
        "\n",
        "이번에는 Keras 라이브러리를 사용하여 선택한 MultiLayer Perceptron(MLP) 아키텍처를 구현해보겠습니다. 극히 단순한 모델부터 복잡한 모델까지 만들어 보실 수 있습니다. 모델을 학습하고 정확도를 구해보세요. \n",
        "<br> 그런 다음 최소 <b>두 개</b>의 파라미터를 튜닝한 후에 다시 모형의 정확도를 구해보고 이전 모델과 비교해보세요. \n",
        "<br> 아래 Cell에서 심장병 데이터 세트를 불러 온 후 이진 분류 모델 (binary classification model) 을 만들어 보세요. 이진 분류 작업에 적절한 손실 함수를 사용하고, 신경망의 마지막 계층에서 적절한 출력값과 활성화 함수를 사용합니다. \n",
        "<br> 세부적인 출력을 사용하여 빠르게 수렴할 수 있도록 모델을 학습해보는 것도 중요합니다. GridSearchCV 또는 RandomSearchCV를 사용하여 모델을 하이퍼 파라미터들을 튜닝해봅니다. (최소 두 개의 하이퍼 파라미터를 튜닝해봅니다) 하이퍼 파라미터 튜닝 시 새로운 각 실험에 대해 코드 셀을 추가하여 작업하는 방법을 배워보았는데, 그대로 이용하지 말고 변형을 해서 보여주고 싶은 내용을 정리해서 보여주세요.  \n",
        "<br> 테스트할 때 하이퍼 파라미터의 각 조합에 대한 정확도를 보고하여 가장 높은 정확도를 얻을 수 있는 결과를 쉽게 확인할 수 있도록 합니다. \n",
        "<br> 이 SC에서 **3점**을 얻으려면 **최소 3개의 파라미터**를 조정해야 합니다.\n",
        "\n",
        "- BatchNormalization을 레이어에 추가하면 성능이 많이 오를 수 있습니다. \n",
        "- 하지만 BatchNormalization을 사용하기 위해서는 Batch_size 옵션을 추가해야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F35sgQ7Cw5y8",
        "inputHidden": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "outputHidden": false
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "df = pd.read_csv('https://ds-lecture-data.s3.ap-northeast-2.amazonaws.com/datasets/heart.csv')\n",
        "df = df.sample(frac=1)\n",
        "print(df.shape)\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDeM_1iEw5y9"
      },
      "outputs": [],
      "source": [
        "# 이 곳에 답안을 작성하시기 바랍니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xUDHLAhId4W8"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "ai12-sc41x-박효정.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4"
    },
    "nteract": {
      "version": "0.23.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}